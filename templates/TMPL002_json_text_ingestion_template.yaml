# This is a template for ingesting CSV files with schema enforcement
# It is used to generate the actions for the pipeline
# within the pipeline all it need to defined are the parameters for the table name and landing folder
# the template will generate the actions for the pipeline

name: TMPL002_json_text_ingestion_template
version: "1.0"
description: "Standard template for ingesting JSON-Text files"

parameters:
  - name: table_name
    required: true
    description: "Name of the table to ingest"
  - name: landing_folder
    required: true
    description: "Name of the landing folder"
  - name: table_properties
    required: false
    description: "Optional table properties as key-value pairs"
    default: {}

actions:
  - name: load_{{ table_name }}_json_text
    type: load
    source:
      type: cloudfiles
      path: "{landing_path}/{{ landing_folder }}"
      format: text
      options:
        wholeText: "true"
    target: vw_{{ table_name }}_raw
    operational_metadata: ["_source_file_path","_processing_timestamp"]
    description: "Load {{ table_name }} from JSON-Text files"

  - name: text_to_json_{{ table_name }}
    type: transform
    transform_type: sql
    source: vw_{{ table_name }}_raw
    target: vw_{{ table_name }}_json
    sql: |
      SELECT
      `value` as raw_json_string,
      from_json(`value`, NULL, map('schemaLocationKey', '{{ table_name }}_schema')) jsonCol,
      _source_file_path,
      _processing_timestamp
      FROM STREAM (vw_{{ table_name }}_raw)

  - name: write_{{ table_name }}_json
    type: write
    source: vw_{{ table_name }}_json
    write_target:
      type: streaming_table
      database: "{catalog}.{raw_schema}"
      table: "{{ table_name }}"
    description: "Write {{ table_name }}_json to raw schema"
    # operational_metadata: ["_processing_timestamp"]